{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "602 Marissa HW10 Neural Network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyVvnw0fLlcc"
      },
      "source": [
        "- Use the diabetes database.\n",
        "- Plot the histograms of the variables. Visualize the difference in distribution between\n",
        "diabetics and non-diabetics with separate plots using Seaborn. Create a subplot of 3 X\n",
        "3 and plot a density plot for each variable. Hide the 9th subplot.\n",
        "- Check the data (null data and number of rows with 0 for each variable). Replace the\n",
        "zero values with NaN. Re-check the data.\n",
        "Replace the NaN values with the mean of the non-missing values.\n",
        "- Standardize the data. Take a look at the mean, std. deviation, and the maximum of\n",
        "each of the transformed variables.\n",
        "- Create a train and test set (80/20).\n",
        "- Use the sequential class from Keras to build the MLP. Add two hidden layers (with the\n",
        "respective node values of 32 and 16, ‘relu’ activation) and one hidden layer (‘sigmoid’\n",
        "activation for output layer). Use ‘adam’ optimizer and ‘binary crossentropy’ loss. What\n",
        "does cross-entropy mean and refer to?\n",
        "- What is the outcome of 100 and 200 epochs? Any difference? Explain.\n",
        "- Evaluate the training and testing sets’ accuracy.\n",
        "- Provide the confusion matrix using Seaborn. What are your conclusions?\n",
        "- Provide the ROC graph. What is the area under the curve? What are your\n",
        "conclusions?\n",
        "- Is the MLP better than a logistic regression model? Do you get a better accuracy with\n",
        "a Random Forest model? Why? Show the outcomes of the different models in a table\n",
        "format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NZQIdOooYJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "54123999-6d26-4632-c0dd-690594691fab"
      },
      "source": [
        "# Use the diabetes database.\n",
        "# Plot the histograms of the variables. Visualize the difference in distribution between\n",
        "# diabetics and non-diabetics with separate plots using Seaborn. Create a subplot of 3 X\n",
        "# 3 and plot a density plot for each variable. Hide the 9th subplot.\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/diabetes2.csv\")\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6WqyNkN-gfc",
        "outputId": "1f8c359f-4041-48f6-8c0e-e61ccb127b78"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArCluvss-cnr"
      },
      "source": [
        "X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
        "y = df['Outcome']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUepaD7RQdNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "outputId": "ac670f48-0292-4919-892a-179b5e9e64d3"
      },
      "source": [
        "X.hist(figsize=(10,8), bins=15)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f13e24f9b90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f13e8062510>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f13e2490210>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f13e2445810>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f13e23fce10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f13e23c0450>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f13e2373a50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f13e2335090>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f13e2341250>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHnYB2R_JNd",
        "outputId": "4f233c84-f25a-4677-cf0d-b15613497b8f"
      },
      "source": [
        "# Check the data (null data and number of rows with 0 for each \n",
        "# variable). Replace the zero values with NaN. Re-check the data.\n",
        "# Replace the NaN values with the mean of the non-missing values.\n",
        "df.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI   DiabetesPedigreeFunction  Age  Outcome\n",
              "17           163      72             41             114      40.9  0.817                     47   1          1\n",
              "15           136      70             32             110      37.1  0.153                     43   1          1\n",
              "2            87       58             16             52       32.7  0.166                     25   0          1\n",
              "                      0              23             0        28.9  0.773                     25   0          1\n",
              "             85       65             0              0        39.6  0.930                     27   0          1\n",
              "                                                                                                            ..\n",
              "5            106      82             30             0        39.5  0.286                     38   0          1\n",
              "             105      72             29             325      36.9  0.159                     28   0          1\n",
              "             104      74             0              0        28.8  0.153                     48   0          1\n",
              "             103      108            37             0        39.2  0.305                     65   0          1\n",
              "0            57       60             0              0        21.7  0.735                     67   0          1\n",
              "Length: 768, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8aOkG93RCvAj",
        "outputId": "3519f997-4541-4d88-d32d-5c91ad1019ab"
      },
      "source": [
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "0              6      148  ...   50        1\n",
              "1              1       85  ...   31        0\n",
              "2              8      183  ...   32        1\n",
              "3              1       89  ...   21        0\n",
              "4              0      137  ...   33        1\n",
              "..           ...      ...  ...  ...      ...\n",
              "763           10      101  ...   63        0\n",
              "764            2      122  ...   27        0\n",
              "765            5      121  ...   30        0\n",
              "766            1      126  ...   47        1\n",
              "767            1       93  ...   23        0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daQtsSGiCu-m"
      },
      "source": [
        " X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age']]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "wUN_ZfaTATcY",
        "outputId": "9d3ce862-24ff-4f6b-88ee-de1972970110"
      },
      "source": [
        "import numpy as np\n",
        "X[df==0] = np.nan\n",
        "X\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3093: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._where(-key, value, inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>137.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "0            6.0    148.0           72.0  ...  33.6                     0.627   50\n",
              "1            1.0     85.0           66.0  ...  26.6                     0.351   31\n",
              "2            8.0    183.0           64.0  ...  23.3                     0.672   32\n",
              "3            1.0     89.0           66.0  ...  28.1                     0.167   21\n",
              "4            NaN    137.0           40.0  ...  43.1                     2.288   33\n",
              "..           ...      ...            ...  ...   ...                       ...  ...\n",
              "763         10.0    101.0           76.0  ...  32.9                     0.171   63\n",
              "764          2.0    122.0           70.0  ...  36.8                     0.340   27\n",
              "765          5.0    121.0           72.0  ...  26.2                     0.245   30\n",
              "766          1.0    126.0           60.0  ...  30.1                     0.349   47\n",
              "767          1.0     93.0           70.0  ...  30.4                     0.315   23\n",
              "\n",
              "[768 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "F0nzmfrKJi3L",
        "outputId": "efd5f095-41cf-4fe0-8d7e-9485cb466d26"
      },
      "source": [
        "X[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']] = X[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age']].fillna(value=X[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age']].mean())\n",
        "X\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>148.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>85.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>29.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>183.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>29.15342</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.494673</td>\n",
              "      <td>137.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.00000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>101.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>48.00000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>122.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>27.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>121.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>126.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>29.15342</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>93.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>31.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "0       6.000000    148.0           72.0  ...  33.6                     0.627   50\n",
              "1       1.000000     85.0           66.0  ...  26.6                     0.351   31\n",
              "2       8.000000    183.0           64.0  ...  23.3                     0.672   32\n",
              "3       1.000000     89.0           66.0  ...  28.1                     0.167   21\n",
              "4       4.494673    137.0           40.0  ...  43.1                     2.288   33\n",
              "..           ...      ...            ...  ...   ...                       ...  ...\n",
              "763    10.000000    101.0           76.0  ...  32.9                     0.171   63\n",
              "764     2.000000    122.0           70.0  ...  36.8                     0.340   27\n",
              "765     5.000000    121.0           72.0  ...  26.2                     0.245   30\n",
              "766     1.000000    126.0           60.0  ...  30.1                     0.349   47\n",
              "767     1.000000     93.0           70.0  ...  30.4                     0.315   23\n",
              "\n",
              "[768 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Sinqsv_BKukx",
        "outputId": "18410420-f645-4ed2-eb6c-3a7222e562ac"
      },
      "source": [
        "#Standardize the data. Take a look at the mean, std. deviation, and \n",
        "# the maximum of each of the transformed variables.\n",
        "X.describe()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.494673</td>\n",
              "      <td>121.686763</td>\n",
              "      <td>72.405184</td>\n",
              "      <td>29.153420</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>32.457464</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.975395</td>\n",
              "      <td>30.435949</td>\n",
              "      <td>12.096346</td>\n",
              "      <td>8.790942</td>\n",
              "      <td>85.021108</td>\n",
              "      <td>6.875151</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.200000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.750000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>121.500000</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.494673</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.202592</td>\n",
              "      <td>29.153420</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>32.400000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  ...  DiabetesPedigreeFunction         Age\n",
              "count   768.000000  768.000000  ...                768.000000  768.000000\n",
              "mean      4.494673  121.686763  ...                  0.471876   33.240885\n",
              "std       2.975395   30.435949  ...                  0.331329   11.760232\n",
              "min       1.000000   44.000000  ...                  0.078000   21.000000\n",
              "25%       2.000000   99.750000  ...                  0.243750   24.000000\n",
              "50%       4.494673  117.000000  ...                  0.372500   29.000000\n",
              "75%       6.000000  140.250000  ...                  0.626250   41.000000\n",
              "max      17.000000  199.000000  ...                  2.420000   81.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_sOWhCITVsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b027a96-1c37-44a0-fa19-3eb00c48a1e9"
      },
      "source": [
        "y = df['Outcome']\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "763    0\n",
              "764    0\n",
              "765    0\n",
              "766    1\n",
              "767    0\n",
              "Name: Outcome, Length: 768, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzTqMEnCRD1J"
      },
      "source": [
        "# - Create a train and test set (80/20)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY_og34RO6_U"
      },
      "source": [
        "# - Use the sequential class from Keras to build the MLP. Add two hidden layers (with the\n",
        "# respective node values of 32 and 16, ‘relu’ activation) and one hidden layer (‘sigmoid’\n",
        "# activation for output layer). Use ‘adam’ optimizer and ‘binary crossentropy’ loss. What\n",
        "# does cross-entropy mean and refer to?\n",
        "\n",
        "from keras.models import Sequential\n",
        "model = Sequential()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTh9EhFtPJGy"
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kzvrew1VqvN"
      },
      "source": [
        "# add first hidden layer\n",
        "model.add(Dense(32,activation='relu',input_dim=8))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzKynisNPOXV"
      },
      "source": [
        "# add second hidden layer \n",
        "model.add(Dense(16, activation='relu'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Xu7nU3UPls"
      },
      "source": [
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKo3ZidEWp4T",
        "outputId": "b4f3f2f5-5c44-4b06-dc72-a1199255a2d2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                288       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 833\n",
            "Trainable params: 833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93s4BOoWWp2z"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53aIzuy1U3Y2"
      },
      "source": [
        "# What does cross entropy mean?\n",
        "Cross Entropy is the use of negative logs on probabilities where a high number means bad models and a low number mean a good model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BJFKjbRRaiP",
        "outputId": "6222c80d-822d-4413-c33a-2279d13be4fc"
      },
      "source": [
        "# - What is the outcome of 100 and 200 epochs? \n",
        "model.fit(X_train, y_train, epochs=200)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 2.8784 - accuracy: 0.4544\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0226 - accuracy: 0.5863\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7907 - accuracy: 0.6107\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7162 - accuracy: 0.6417\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.6596\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6629\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7534 - accuracy: 0.6694\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6612\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7134\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6971\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6954\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6726\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7020\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6759\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6922\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7434 - accuracy: 0.6450\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6857\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7020\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.6954\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6954\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.6987\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7199\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7150\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.6971\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7134\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7068\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7248\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.6971\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7150\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6840\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7280\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7264\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7036\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6922\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7199\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7166\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7199\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7248\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7199\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7264\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7036\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7313\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7166\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7199\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7182\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7036\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7264\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7003\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7296\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7345\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7231\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7150\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7264\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7476\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7215\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7329\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7313\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7443\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7362\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7313\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7492\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7443\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7280\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7215\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7378\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7443\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7362\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7345\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7362\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7378\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7476\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7410\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7296\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7166\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7199\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7524\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7410\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7264\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7280\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7313\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7508\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7410\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7443\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7280\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6824\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7150\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7248\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7443\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7264\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7459\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7541\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7541\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7427\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7329\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7476\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7329\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7476\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7492\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7410\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7476\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7655\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7443\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7557\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7524\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7362\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7296\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7508\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7248\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7557\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7378\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7590\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7524\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7541\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7541\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7687\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7199\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7345\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7524\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7606\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7345\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7329\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7264\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7280\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7557\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7622\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7508\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7492\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7638\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7459\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7394\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7410\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7427\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7476\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7427\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7508\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7296\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7492\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7166\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7248\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7541\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7443\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7427\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7459\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7394\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7687\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7590\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7524\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7459\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7687\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7378\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7622\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7508\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7557\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7590\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7427\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7704\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7557\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7687\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7622\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7752\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7687\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7362\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7671\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7638\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7606\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7671\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7687\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7704\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7215\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7655\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7508\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7752\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7655\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7590\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7769\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7736\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7655\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7655\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7704\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7590\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7687\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7655\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7655\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7769\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7687\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7606\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7606\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7655\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7606\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7622\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7622\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7394\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7573\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7915\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7590\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7671\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7606\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7687\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f136a6df6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImXak15bX9CB",
        "outputId": "789830fe-b0a2-463f-d94d-7817a8ad7693"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7655\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7590\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7736\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7818\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7557\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7818\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7785\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7590\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7736\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7655\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7671\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7557\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7655\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7736\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7655\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7785\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7541\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7720\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7834\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7671\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7508\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7410\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7622\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7850\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7752\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7850\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7785\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7736\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7622\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7443\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7850\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7638\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7818\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7622\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7704\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7720\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7915\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7769\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7850\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7655\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7720\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7671\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7622\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7752\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7638\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7752\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7329\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7704\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7606\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7866\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7769\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7964\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7704\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7850\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7476\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7899\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7834\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7866\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7704\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7850\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7785\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7590\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7590\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7752\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7850\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7785\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7801\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7704\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7769\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7785\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7948\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7883\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7850\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7932\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7997\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7948\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7818\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7964\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7704\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8029\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7915\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7687\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7785\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7964\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7704\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7573\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7915\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7752\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7866\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7899\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7850\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7801\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7932\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7834\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7769\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7834\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7883\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7834\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7932\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7769\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1366f29390>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOUYRAXsXh16"
      },
      "source": [
        "### Any difference? Explain.<br>\n",
        "The Epoch 200 1/200 has high loss 5.3161 low accuracy .5863. Eventually drop when 200/200 losst .4734 accuracy .7476\n",
        "The Epcok 100 1/100 loss .4715 accuracy .7573. 100/100 loss .4536 accuracy .7850.<br> \n",
        "the accuracy scores improves as the  evaluation increases(fraction gets bigger). The 200 epoch began with big loss and lower accuracy than the 100 epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7L80YM-Rc5S",
        "outputId": "4c29267a-f277-48ea-b3ac-50a9734517cf"
      },
      "source": [
        "# - Evaluate the training and testing sets’ accuracy\n",
        "# Train and Test accuracy\n",
        "scores = model.evaluate(X_train,y_train)\n",
        "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1]*100))\n",
        "scores = model.evaluate(X_test,y_test)\n",
        "print(\"Testing Accuracy: %.2f%%\\n\" % (scores[1]*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7801\n",
            "Training Accuracy: 78.01%\n",
            "\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.7078\n",
            "Testing Accuracy: 70.78%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aY6GcvPL9Uf"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_log = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_log)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "idwPX518Pw5a",
        "outputId": "9fa2c936-fa66-4cb4-eef3-1681767870c4"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['False','True'])\n",
        "ax.yaxis.set_ticklabels(['False','True'])\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGPbPAt4Rpz9"
      },
      "source": [
        "# - Is the MLP better than a logistic regression model? Do you get a better accuracy with\n",
        "# a Random Forest model? Why? Show the outcomes of the different models in a table\n",
        "# format."
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtXxUT5mSRvQ"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOaaMMA_SRE6"
      },
      "source": [
        "log_accuracy = accuracy_score(y_test, y_pred_log)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwA-ymJMvi__"
      },
      "source": [
        "### Is the MLP better than a logistic regression model?<br>\n",
        "No, the MLP doesn't have a better model than logistic regression<br>\n",
        "\n",
        "### Do you get a better accuracy with a Random Forest model?<br>\n",
        "No, the MLP model is not any better than logistic nor Random Forest<br>\n",
        "\n",
        "### Why? Show the outcomes of the different models in a table format.<br>\n",
        "The random forest's score is almost the same but the neural network is slightly lower in accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "C_ndXGsKmbrC",
        "outputId": "095b7224-4aa6-4abd-e55f-67e6cb3b02ae"
      },
      "source": [
        "acc_scores = pd.DataFrame({\"Random Forest \": [rf_accuracy], \"Logistic Regression \": [log_accuracy], \"Neural Network \": [scores[1]]})  \n",
        "acc_scores"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Neural Network</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.766234</td>\n",
              "      <td>0.75974</td>\n",
              "      <td>0.707792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Random Forest   Logistic Regression   Neural Network \n",
              "0        0.766234               0.75974         0.707792"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}